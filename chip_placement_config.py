"""
Configuration for Continuous SDDS Chip Placement Training

This config enables unsupervised chip placement optimization using:
- Gaussian diffusion (continuous positions)
- ContinuousHead (outputs mean/log_var)
- ChipPlacementEnergy (HPWL + constraints)
- PPO training with GAE

Usage:
    python argparse_ray_main.py --EnergyFunction ChipPlacement \
                                  --IsingMode Chip_20_components \
                                  --train_mode PPO \
                                  --graph_mode normal \
                                  --noise_potential gaussian \
                                  --GPUs 0
"""

# Base configuration for chip placement
CHIP_PLACEMENT_CONFIG = {
    # ===== Problem Settings =====
    "mode": "Diffusion",
    "dataset_name": "Chip_20_components",  # Will generate 20-50 components per instance
    "problem_name": "ChipPlacement",       # Must match EnergyFunction registry

    # ===== Continuous Mode Settings =====
    "continuous_dim": 2,                   # 2D positions (x, y)
    "n_bernoulli_features": 2,             # Set to continuous_dim for compatibility

    # ===== Diffusion Settings =====
    "noise_potential": "gaussian",         # GaussianNoise for continuous
    "n_diffusion_steps": 50,               # Number of diffusion steps T
    "beta_factor": 1.0,                    # Noise schedule factor
    "diff_schedule": "linear",             # "linear" or "cosine"
    "time_encoding": "sinusoidal",         # Better than one_hot for many steps

    # ===== Training Settings =====
    "train_mode": "PPO",                   # Must be PPO for RL-based training
    "lr": 1e-4,                            # Learning rate
    "lr_schedule": "cosine",               # Learning rate schedule
    "stop_epochs": 1000,                   # Maximum training epochs
    "batch_size": 16,                      # Number of graphs per batch (reduce for memory)
    "N_basis_states": 10,                  # Number of parallel states per graph
    "n_test_basis_states": 20,             # More states for evaluation

    # ===== PPO Hyperparameters =====
    "inner_loop_steps": 2,                 # Number of PPO update iterations
    "minib_diff_steps": 10,                # Minibatch size in diffusion steps
    "minib_basis_states": 5,               # Minibatch size in basis states
    "TD_k": 3,                             # GAE parameter (Î» decay)
    "clip_value": 0.2,                     # PPO clip epsilon
    "value_weighting": 0.65,               # Value loss coefficient (c1)
    "mov_average": 0.0009,                 # Moving average for normalization
    "grad_clip": True,                     # Gradient clipping

    # ===== Network Architecture =====
    "graph_mode": "normal",                # Use EncodeProcessDecode GNN
    "n_hidden_neurons": 64,                # Hidden dimension
    "n_features_list_prob": [64, 64],      # ContinuousHead will use this
    "n_features_list_nodes": [64, 64, 64], # Node update layers
    "n_features_list_edges": [64, 64],     # Edge update layers
    "n_features_list_messages": [64, 64],  # Message passing layers
    "n_features_list_encode": [64, 64],    # Encoder layers
    "n_features_list_decode": [64, 64],    # Decoder layers
    "n_message_passes": 5,                 # Number of message passing steps
    "message_passing_weight_tied": False,  # Independent weights per layer
    "linear_message_passing": True,        # Use linear layers
    "edge_updates": False,                 # No edge feature updates
    "mean_aggr": True,                     # Mean aggregation in message passing
    "graph_norm": True,                    # Graph normalization

    # ===== Input Features =====
    "random_node_features": True,          # Random node features for exploration
    "n_random_node_features": 5,           # Number of random features
    "time_conditioning": True,             # Condition on diffusion timestep

    # ===== Energy Function Settings =====
    # ChipPlacementEnergy parameters
    "overlap_weight": 10.0,                # Penalty weight for component overlaps
    "boundary_weight": 10.0,               # Penalty weight for out-of-bounds
    "canvas_width": 2.0,                   # Canvas width (x: [-1, 1])
    "canvas_height": 2.0,                  # Canvas height (y: [-1, 1])
    "canvas_x_min": -1.0,                  # Canvas x minimum
    "canvas_y_min": -1.0,                  # Canvas y minimum

    # ===== Data Settings =====
    "seed": 123,                           # Random seed
    "relaxed": True,                       # Use relaxed (continuous) states
    "jit": True,                           # JIT compilation

    # ===== Annealing Settings (Optional) =====
    # For continuous chip placement, we typically don't use temperature annealing
    # But these are kept for compatibility
    "T_max": 0.0,                          # Maximum temperature (0 for no annealing)
    "T_target": 0.0,                       # Target temperature
    "N_warmup": 0,                         # Warmup epochs
    "N_anneal": 0,                         # Annealing epochs
    "N_equil": 0,                          # Equilibration epochs
    "AnnealSchedule": "linear",            # Annealing schedule

    # ===== Advanced Settings =====
    "loss_alpha": 0.0,                     # KL weighting (0 for pure RL)
    "MCMC_steps": 0,                       # MCMC refinement steps (optional)
    "proj_method": "None",                 # Projection method ("None", "CE", "feasible")
    "sampling_temp": 0.0,                  # Sampling temperature
    "n_sampling_rounds": 1,                # Sampling rounds
    "bfloat16": False,                     # Use bfloat16 (set True for TPU/A100)

    # ===== Logging =====
    "wandb": True,                         # Weights & Biases logging
    "project_name": "ChipPlacement_SDDS",  # W&B project name
}


# Example configurations for different scales
SMALL_CHIP_CONFIG = {
    **CHIP_PLACEMENT_CONFIG,
    "dataset_name": "Chip_10_components",
    "batch_size": 32,
    "N_basis_states": 20,
    "n_diffusion_steps": 30,
}

MEDIUM_CHIP_CONFIG = {
    **CHIP_PLACEMENT_CONFIG,
    "dataset_name": "Chip_20_components",
    "batch_size": 16,
    "N_basis_states": 10,
    "n_diffusion_steps": 50,
}

LARGE_CHIP_CONFIG = {
    **CHIP_PLACEMENT_CONFIG,
    "dataset_name": "Chip_50_components",
    "batch_size": 8,
    "N_basis_states": 5,
    "n_diffusion_steps": 100,
    "n_hidden_neurons": 128,
    "n_message_passes": 8,
}

# Dummy config for quick testing
DUMMY_CHIP_CONFIG = {
    **CHIP_PLACEMENT_CONFIG,
    "dataset_name": "Chip_dummy",
    "batch_size": 4,
    "N_basis_states": 5,
    "n_diffusion_steps": 10,
    "stop_epochs": 10,
    "n_message_passes": 2,
    "n_hidden_neurons": 32,
}


def get_chip_placement_config(scale="medium"):
    """
    Get chip placement configuration for specified scale.

    Args:
        scale: "small", "medium", "large", or "dummy"

    Returns:
        config dict
    """
    configs = {
        "small": SMALL_CHIP_CONFIG,
        "medium": MEDIUM_CHIP_CONFIG,
        "large": LARGE_CHIP_CONFIG,
        "dummy": DUMMY_CHIP_CONFIG,
    }

    if scale not in configs:
        raise ValueError(f"Unknown scale '{scale}'. Choose from {list(configs.keys())}")

    return configs[scale]


# Command line examples
COMMAND_LINE_EXAMPLES = """
# Small chip (10 components, fast training)
python argparse_ray_main.py \\
    --EnergyFunction ChipPlacement \\
    --IsingMode Chip_10_components \\
    --train_mode PPO \\
    --graph_mode normal \\
    --noise_potential gaussian \\
    --n_diffusion_steps 30 \\
    --batch_size 32 \\
    --n_basis_states 20 \\
    --GPUs 0

# Medium chip (20-50 components, recommended)
python argparse_ray_main.py \\
    --EnergyFunction ChipPlacement \\
    --IsingMode Chip_20_components \\
    --train_mode PPO \\
    --graph_mode normal \\
    --noise_potential gaussian \\
    --n_diffusion_steps 50 \\
    --batch_size 16 \\
    --n_basis_states 10 \\
    --GPUs 0

# Dummy (quick test, 5 components)
python argparse_ray_main.py \\
    --EnergyFunction ChipPlacement \\
    --IsingMode Chip_dummy \\
    --train_mode PPO \\
    --graph_mode normal \\
    --noise_potential gaussian \\
    --n_diffusion_steps 10 \\
    --batch_size 4 \\
    --n_basis_states 5 \\
    --stop_epochs 10 \\
    --GPUs 0
"""

if __name__ == "__main__":
    print("=== Chip Placement SDDS Configuration ===\n")
    print("Default config (medium scale):")
    import pprint
    pprint.pprint(MEDIUM_CHIP_CONFIG)

    print("\n\n=== Command Line Examples ===")
    print(COMMAND_LINE_EXAMPLES)
